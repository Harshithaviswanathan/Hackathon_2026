# ğŸ§  Build â†’ Break â†’ Improve: Synthetic Image Detector

### ğŸ“Œ Overview
This project implements a complete pipeline for detecting AI-generated images and evaluating model robustness.  
The goal is to simulate a real-world AI security workflow:
  - **Build** a detector to classify images as REAL or FAKE
  - **Break** the detector using adversarial modifications
  - **Improve** the system by analyzing vulnerabilities and proposing defenses
ğŸ”— **Delpoyed link:** https://shamanistic-deirdre-noncalculably.ngrok-free.dev

### ğŸ—‚ï¸ Dataset
**CIFAKE** â€” 120k images (Real vs Synthetic, 32Ã—32 RGB)

### ğŸ“Š Methodology
- **Base Model:** ResNet-18 (binary classifier)
- **Metrics:** Accuracy, Precision, Recall, F1-score, Confusion Matrix
- **Explainability:** Grad-CAM / saliency maps

### ğŸ›¡ï¸ Adversarial Experiments
- Gaussian noise perturbations  
- Gaussian blur (artifact suppression)  
- FGSM attack  
These experiments show the detectorâ€™s sensitivity to high-frequency artifacts.

### ğŸš€ Proposed Improvement
Adversarial training with frequency-aware augmentations to improve robustness.

### ğŸ› ï¸ Tech Stack
Python, PyTorch, Torchvision, NumPy, Matplotlib, Scikit-learn
