{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9VFMhiXqAzS",
        "outputId": "6682e674-67cb-4d6f-969e-afc96603107b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok torchvision --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT_ET1KFqQVV",
        "outputId": "a9c70fee-b102-4dfd-a61a-6df958f68eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transform for model input\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std=[0.229,0.224,0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "class_names = [\"FAKE\", \"REAL\"]\n",
        "\n",
        "# Load model\n",
        "@st.cache_resource\n",
        "def load_model(path):\n",
        "    model = models.resnet18(weights=None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, img_tensor):\n",
        "    img_tensor = transform(img_tensor).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(img_tensor)\n",
        "        probs = torch.softmax(out, dim=1)\n",
        "    return probs.cpu().numpy()[0]\n",
        "\n",
        "def add_noise(img_tensor, epsilon):\n",
        "    noise = torch.randn_like(img_tensor) * epsilon\n",
        "    return torch.clamp(img_tensor + noise, 0, 1)\n",
        "\n",
        "def blur_image(img_tensor, k):\n",
        "    return TF.gaussian_blur(img_tensor, kernel_size=k)\n",
        "\n",
        "def fgsm_attack(image, epsilon):\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    normalized = transform(transforms.ToPILImage()(image.squeeze(0))).unsqueeze(0).to(device)\n",
        "    normalized.requires_grad = True\n",
        "    output = model(normalized)\n",
        "    loss = nn.CrossEntropyLoss()(output, torch.tensor([1]).to(device))\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    perturbed = normalized + epsilon * normalized.grad.sign()\n",
        "    mean = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1).to(device)\n",
        "    std = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1).to(device)\n",
        "    perturbed = perturbed * std + mean\n",
        "    perturbed = torch.clamp(perturbed, 0, 1)\n",
        "    return perturbed.squeeze(0).detach().cpu()\n",
        "\n",
        "\n",
        "# UI\n",
        "st.title(\"üõ° Deepfake Detection ‚Äì Robust AI\")\n",
        "\n",
        "model_choice = st.sidebar.selectbox(\n",
        "    \"Select Model\",\n",
        "    [\"Baseline Model\", \"Robust Model\"]\n",
        ")\n",
        "\n",
        "attack_choice = st.sidebar.selectbox(\n",
        "    \"Apply Attack\",\n",
        "    [\"None\", \"Gaussian Noise\", \"Blur\", \"FGSM Attack\"]\n",
        ")\n",
        "\n",
        "epsilon = st.sidebar.slider(\"Noise Strength\", 0.0, 0.5, 0.05)\n",
        "blur_k = st.sidebar.slider(\"Blur Kernel Size\", 3, 15, 5, step=2)\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Image\", type=[\"jpg\",\"png\",\"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "\n",
        "    # Load correct model\n",
        "    if model_choice == \"Baseline Model\":\n",
        "        model = load_model(\"best_model.pth\")\n",
        "    else:\n",
        "        model = load_model(\"robust_model_multidefense.pth\")\n",
        "\n",
        "    # Convert to tensor (without normalization for attack)\n",
        "    img_tensor = transforms.ToTensor()(image)\n",
        "\n",
        "    # Apply attack if selected\n",
        "    if attack_choice == \"Gaussian Noise\":\n",
        "        img_tensor = add_noise(img_tensor, epsilon)\n",
        "        st.write(\"Applied Gaussian Noise\")\n",
        "\n",
        "    elif attack_choice == \"Blur\":\n",
        "        img_tensor = blur_image(img_tensor, blur_k)\n",
        "        st.write(\"Applied Blur\")\n",
        "    \n",
        "    elif attack_choice == \"FGSM Attack\":\n",
        "        img_tensor = fgsm_attack(img_tensor, epsilon)\n",
        "        st.write(\"Applied FGSM attack\")\n",
        "\n",
        "    # Convert tensor back to PIL for prediction pipeline\n",
        "    modified_image = transforms.ToPILImage()(img_tensor)\n",
        "\n",
        "    # Show modified image\n",
        "    st.image(modified_image, caption=\"Image Used for Prediction\", use_column_width=True)\n",
        "\n",
        "    # ‚úÖ Now prediction is done on the correct image\n",
        "    probs = predict(model, modified_image)\n",
        "\n",
        "    st.subheader(\"Prediction\")\n",
        "    st.write(f\"REAL Confidence: {probs[1]:.4f}\")\n",
        "    st.write(f\"FAKE Confidence: {probs[0]:.4f}\")\n",
        "\n",
        "    predicted_class = class_names[np.argmax(probs)]\n",
        "    st.success(f\"Predicted: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd39bTULq3jx"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"3A1nlDfpFGDoLZDL1300DGXMCbB_3xD77Sa4zPz2sLFFfhQim\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Czg_D2hrQxE",
        "outputId": "63f40dba-b336-4b4c-e68d-eea85f9d6634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://shamanistic-deirdre-noncalculably.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQbpA5kcrUpk",
        "outputId": "54c4e92d-2dff-4c0a-c0f9-095ce4d00a11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-22T14:45:48+0000 lvl=warn msg=\"failed to open private leg\" id=ead28944a4fd privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-02-22T14:45:48+0000 lvl=warn msg=\"failed to open private leg\" id=33d073afcbda privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Streamlit App URL: NgrokTunnel: \"https://shamanistic-deirdre-noncalculably.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# üîê Add your ngrok token here\n",
        "ngrok.set_auth_token(\"PASTE_YOUR_TOKEN_HERE\")\n",
        "\n",
        "# Kill existing streamlit\n",
        "!pkill streamlit\n",
        "\n",
        "# Start Streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Your Streamlit App URL:\", public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
